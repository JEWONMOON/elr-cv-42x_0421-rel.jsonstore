{
    "message_id": 2055,
    "session_id": "엘리아르 코어 통합 요청_20250510023904",
    "session_title": "엘리아르 코어 통합 요청",
    "pair_id": 209,
    "parent_id": 2054,
    "author": "ChatGPT",
    "role": "answer",
    "tags": [],
    "content": "\"name\": \"update_llm_code\", \"type\": \"code/python\", \"content\": \" llm.py 수정 버전 DeepSeek 모델 적용 n nfrom transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig n n 4bit 양자화 설정 nbnb_config BitsAndBytesConfig n load_in_4bit True, n bnb_4bit_compute_dtype \"float16 \", n n n 모델 로드 nmodel AutoModelForCausalLM.from_pretrained n \"D:/Eliar_server/models/deepseek \", 경로 수정! n device_map \"auto \", n quantization_config bnb_config, n trust_remote_code True n n n 토크나이저 로드 ntokenizer AutoTokenizer.from_pretrained n \"D:/Eliar_server/models/deepseek \", 경로 수정! n trust_remote_code True n n n 텍스트 생성 파이프라인 ngenerator pipeline n \"text-generation \", n model model, n tokenizer tokenizer, n device_map \"auto \" n n n 응답 생성 함수 ndef generate_response prompt: str - str: n inputs tokenizer prompt, return_tensors \"pt \" .to model.device n input_ids inputs \"input_ids \" n attention_mask inputs \"attention_mask \" n n outputs model.generate n input_ids input_ids, n attention_mask attention_mask, n max_length 512, n do_sample True, n top_p 0.95 n n return tokenizer.decode outputs 0 , skip_special_tokens True \""
}