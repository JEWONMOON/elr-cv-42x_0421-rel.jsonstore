{
    "message_id": 1688,
    "session_id": "엘리아르 코어 통합 요청_20250510023904",
    "session_title": "엘리아르 코어 통합 요청",
    "pair_id": 89,
    "parent_id": null,
    "author": "user",
    "role": "question",
    "tags": [],
    "content": "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer model AutoModelForCausalLM.from_pretrained \"D:/Eliar_server/models/gecko-7b\", device_map \"auto\", torch_dtype \"auto\", 메모리 자동 최적화 trust_remote_code True 필요하면 True tokenizer AutoTokenizer.from_pretrained \"D:/Eliar_server/models/gecko-7b\", trust_remote_code True generator pipeline \"text-generation\", model model, tokenizer tokenizer, device_map \"auto\" def generate_response prompt : inputs tokenizer prompt, return_tensors \"pt\" .to model.device outputs model.generate inputs, max_length 512, do_sample True, top_p 0.95 return tokenizer.decode outputs 0 , skip_special_tokens True"
}