{
    "message_id": 16772,
    "session_id": "피곤함과 감정의 대화_20250510023908",
    "session_title": "피곤함과 감정의 대화",
    "pair_id": 297,
    "parent_id": null,
    "author": "user",
    "role": "question",
    "tags": [],
    "content": "해결 방법 1. 내용을 자른다 질문을 보낼 때 messages를 모두 보내는 것이 아닌 오래된 질문을 하나씩 빼서 보내는 겁니다. 예를 들면 최근 2개의 대화만 보내는 방법이 있죠 아래 예시처럼 최근 메시지만 잘라서 보내면 토큰이 어느정도 유지될 겁니다. import openai def send_question openai: any, messages: list dict - str: completion openai.ChatCompletion.create model \"gpt-3.5-turbo\", messages messages, return completion.choices 0 .message.content if __name__ '__main__': openai.api_key ' openai_key ' messages: list dict while True: question input if question '': break if len messages 4: messages messages len messages -4: 최근 2개의 대화만 가져오기 messages.append 'role': 'user', 'content': question answer send_question openai, messages print '--------------ANSWER-------------' print answer print '---------------------------------' messages.append 'role': 'assistant', 'content': answer 그런데 이렇게 하면 문제가 있습니다. 최근 2개의 대화에 대한 맥락은 가지고 있지만 유저가 처음에 했던 질문에 대한 질문을 다시 하면 AI는 엉뚱한 답변을 하겠죠? 처음에 했던 대화는 잘렸으니까요. 2. 대화를 요약한다. 정확도는 다소 떨어질 수 있지만 대화를 요약해서 토큰을 줄이는 방법도 있습니다. 다음 예시에서는 summarize 함수로 AI의 응답을 요약하는 기능을 추가하고 테스트했는데, 맥락이 꽤 잘 이어집니다. import openai def summarize openai: any, answer: str - str: completion openai.ChatCompletion.create model \"gpt-3.5-turbo\", messages 'role': 'user', 'content': f'이 내용 한국어로 한 문장으로 요약해줘 n answer n ' , return completion.choices 0 .message.content def send_question openai: any, messages: list dict - str: completion openai.ChatCompletion.create model \"gpt-3.5-turbo\", messages messages, return completion.choices 0 .message.content if __name__ '__main__': openai.api_key ' openai_key ' messages: list dict while True: question input if question '': break messages.append 'role': 'user', 'content': question answer send_question openai, messages print '--------------ANSWER-------------' print answer print '---------------------------------' summarized summarize openai, answer print '------------SUMMARIZED-----------' print summarized print '---------------------------------' messages.append 'role': 'assistant', 'content': summarized 금액 차이는 다음과 같습니다. 요약하는 과정에서도 비용이 추가되는 점을 감안해도 같은 같은 질문을 이어갔을 때 2배 저렴하게 이용할 수 있습니다. 영어로 하면 더 싸다 token은 영어로 질문하고, 답변했을 때 더 저렴합니다. 그래서 DeepL API 를 사용해서 중간에 번역을 하면 토큰을 더 아낄 수 있습니다. 하지만 프로그래밍의 경우 코드까지 번역될 수 있어서 코드블록 내의 내용은 번역하지 않는 게 좋습니다. 한글 499 영어 281 한글 질문 \"prompt_tokens\": 140, \"completion_tokens\": 359, \"total_tokens\": 499 Response def fib n : _curr 0 _next 1 for _ in range n : _temp _next _next 값을 저장해두어야 함 _next _curr _next _curr _temp 이전에 저장된 _next 값을 사용함 return _curr print fib 5 위 코드에서는 _next 값을 이전에 저장해두었다가 이전 값 _curr 과 더한 후, _curr에 이전 _next 값을 대입하는 방식으로 수행한다. 이는 피보나치 수열에서 각 항이 바로 전 두 항의 합이기 때문에, 이전 항 _curr 과 그 이전 항 _temp 을 이용하여 다음 항 _next 을 계산하는 방식이다. n n원래의 코드에서는 _next 값을 계산할 때 _curr와 _next를 더한 값을 이용했다. 이 경우 _curr는 이전 _next 값에 현재의 _next 값을 더한 값이 되어버리기 때문에, 다음 계산에서 오류가 발생한다. 따라서 _next 값을 계산하기 전 새로운 변수인 _temp에 _next 값을 저장해두고, _next를 계산한 후 _curr 값에는 이전 _next 값을 대입하는 방식을 이용해야 한다. \"prompt_tokens\": 112, \"completion_tokens\": 169, \"total_tokens\": 281 영어 질문 Response The code logic is incorrect. In each iteration of the loop, the current value should be updated with the next value, and the next value should be updated with the sum of the current and next values. However, the current value is being updated with the current plus next value, which leads to an incorrect sum. n nTo fix this, we need to swap the order of the statements that update the current and next values. The corrected code is shown below: def fib n : _curr 0 _next 1 for _ in range n : _curr, _next _next, _curr _next return _curr print fib 5 With this corrected code, we get the correct output of 5 as the n-th Fibonacci number. 결론 잘 섞어서 쓰는 게 좋습니다. 어떤 서비스는 질문과 답변의 정확성이 중요할 수 있고, 어떤 서비스는 정확도는 떨어져도 그럴싸한 답변이 필요한 서비스도 있을 수 있습니다. 그래서 초과 스펙이 되지 않도록 기존 서비스의 평균 대화 수, 텍스트 수를 분석해서 적절한 솔루션을 찾는 것이 중요합니다."
}